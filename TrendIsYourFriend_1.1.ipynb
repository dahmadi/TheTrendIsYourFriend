{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries \n",
    "\n",
    "import pandas as pd \n",
    "import os\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np \n",
    "from scipy.signal import argrelextrema\n",
    "import alpaca_trade_api as tradeapi \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mpdates\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "from dotenv import load_dotenv\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "783a380b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env file\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fac7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Alpaca API key and secret passwords\n",
    "\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85206f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate REST API\n",
    "\n",
    "api = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version = \"v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10584310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Stock Data from Alpacas\n",
    "# Establish time frame (5 minute)\n",
    "\n",
    "time_frame = \"5min\"\n",
    "\n",
    "# Identify what stock symbol is trading\n",
    "\n",
    "stock_symbol = \"QQQ\"\n",
    "\n",
    "# Identify what start date to begin data analysis\n",
    "# JAN 27 27 2021 GameStop event (GME) are we still doing this?\n",
    "\n",
    "start_date = pd.Timestamp(\"2021-02-03\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "# Identify what end date to finalize data analysis\n",
    "\n",
    "end_date = pd.Timestamp(\"2021-02-04\", tz=\"America/New_York\").isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e86837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call daily stock data\n",
    "\n",
    "def get_stock_data(api, stock_symbol, time_frame, current_date_iso, next_day_date_iso):\n",
    "    \n",
    "    # Assuming api.get_bars returns a DataFrame with a 'df' attribute\n",
    "    \n",
    "    stock_data = api.get_bars(\n",
    "        stock_symbol, \n",
    "        time_frame, \n",
    "        start=current_date_iso, \n",
    "        end=next_day_date_iso\n",
    "        ).df\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "# stock_data = get_stock_data(api, stock_symbol, time_frame, start_date, end_date)\n",
    "\n",
    "# Displays the information pulled for working through code\n",
    "\n",
    "# stock_data.info()\n",
    "# display(stock_data.head())\n",
    "# display(stock_data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee041b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare daily stock data to identify double top/bottom patterns and prepare for targets\n",
    "# Includes establishing a polynomial fit and assigning new columns for localized min/max\n",
    "\n",
    "# Polynomial Degree\n",
    "\n",
    "polynomial_degree = 15\n",
    "\n",
    "def polynomial_min_max_fit(stock_data, polynomial_degree):\n",
    "    \n",
    "    min_length = min(len(stock_data.index), len(stock_data['close']))\n",
    "    x_data = np.arange(min_length)\n",
    "\n",
    "    # Polynomial fitting\n",
    "    polynomial_coefficients_open = np.polyfit(x_data, stock_data['open'][:min_length], polynomial_degree)\n",
    "    polynomial_coefficients_high = np.polyfit(x_data, stock_data['high'][:min_length], polynomial_degree)\n",
    "    polynomial_coefficients_low = np.polyfit(x_data, stock_data['low'][:min_length], polynomial_degree)\n",
    "    polynomial_coefficients_close = np.polyfit(x_data, stock_data['close'][:min_length], polynomial_degree)\n",
    "\n",
    "    # Evaluate the polynomial for plotting\n",
    "    y_polynomial_open = np.polyval(polynomial_coefficients_open, x_data)\n",
    "    y_polynomial_high = np.polyval(polynomial_coefficients_high, x_data)\n",
    "    y_polynomial_low = np.polyval(polynomial_coefficients_low, x_data)\n",
    "    y_polynomial_close = np.polyval(polynomial_coefficients_close, x_data)\n",
    "\n",
    "    # Identify local extrema for polynomial fit data (minima and maxima)\n",
    "    local_poly_minima = argrelextrema(y_polynomial_close, np.less, order=5)[0]\n",
    "    local_poly_maxima = argrelextrema(y_polynomial_close, np.greater, order=5)[0]\n",
    "\n",
    "    # Convert the close price polynomial fit data into a dataframe\n",
    "    # This is done for OHLC poly fit data\n",
    "\n",
    "    poly_df = pd.DataFrame(y_polynomial_open)\n",
    "    columns = ['poly_fit_open']\n",
    "    poly_df.columns = columns\n",
    "    poly_df = poly_df.assign(poly_fit_high = y_polynomial_high)\n",
    "    poly_df = poly_df.assign(poly_fit_low = y_polynomial_low)\n",
    "    poly_df = poly_df.assign(poly_fit_close = y_polynomial_close)\n",
    "\n",
    "    # Reset the index of the original updated ticker dataframe to concat with the polynomial dataframe that does not include a timeseries\n",
    "    # This will ensure that the indexed intergers of the ploynomial fit align with the time each data point corresponds to\n",
    "\n",
    "    updated_stock_data = stock_data.reset_index()\n",
    "    updated_stock_data = pd.concat([updated_stock_data, poly_df], axis='columns', join='inner')\n",
    "    updated_stock_data.head()\n",
    "\n",
    "    # Add minima and maxima column to the DataFrame\n",
    "\n",
    "    updated_stock_data[\"minima\"] = 0\n",
    "    updated_stock_data[\"maxima\"] = 0\n",
    "    updated_stock_data.head()\n",
    "\n",
    "    # Mark rows with local minima as 1 in the 'minima' column\n",
    "\n",
    "    for index in local_poly_minima:\n",
    "        updated_stock_data.at[index, 'minima'] = -1\n",
    "\n",
    "    for index in local_poly_maxima:\n",
    "        updated_stock_data.at[index, \"maxima\"] = 1\n",
    "\n",
    "    # Create Target Columns - Double Top Target & Double Bottom Target\n",
    "        \n",
    "    updated_stock_data[\"dbl_top_target\"] = 0\n",
    "    updated_stock_data[\"dbl_bot_target\"] = 0\n",
    "\n",
    "    del poly_df\n",
    "    del x_data\n",
    "    del local_poly_maxima\n",
    "    del local_poly_minima\n",
    "    del min_length\n",
    "    del columns\n",
    "    \n",
    "    return updated_stock_data\n",
    "\n",
    "#, min_length, y_polynomial_close, local_poly_minima, local_poly_maxima\n",
    "\n",
    "# updated_stock_data, min_length, y_polynomial_close, local_poly_minima, local_poly_maxima = polynomial_min_max_fit(stock_data,polynomial_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5a2dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot data\n",
    "# # Plot the stock data and identified minima\n",
    "\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# plt.plot(stock_data.index, stock_data[\"close\"], label='Close Prices', alpha=0.7)\n",
    "\n",
    "# # # Plot polynomial fit\n",
    "\n",
    "# plt.plot(stock_data.index[:min_length], y_polynomial_close, '-', markersize=1.0, color='black', alpha=0.9, label='Polynomial Fit')\n",
    "\n",
    "# # # Plot red dots at local minima and blue dots at local maxima\n",
    "\n",
    "# plt.scatter(stock_data.index[local_poly_minima], y_polynomial_close[local_poly_minima], color='red', label='Local Minima')\n",
    "# plt.scatter(stock_data.index[local_poly_maxima],y_polynomial_close[local_poly_maxima], color=\"blue\", label = \"Local Maxima\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c07bc303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time independent DF for double top/bottom identification\n",
    "# Timestamp remains a column, but can identify pattern from peak to peak immediately\n",
    "\n",
    "def time_independent_data(updated_stock_data):\n",
    "\n",
    "    time_independent_df = []\n",
    "    time_independent_df = pd.DataFrame(time_independent_df, columns = [\"timestamp\",\"close\",\"high\",\"low\",\"trade_count\",\"open\",\"volume\",\"vwap\",\"poly_fit_open\",\"poly_fit_high\",\"poly_fit_low\",\"poly_fit_close\",\"minima\",\"maxima\",\"dbl_top_target\",\"dbl_bot_target\"])\n",
    "\n",
    "    for index, row in islice(updated_stock_data.iterrows(), 0, None):\n",
    "\n",
    "        # Assign to rows only those that contain local min or max\n",
    "\n",
    "        if (updated_stock_data.at[index,\"minima\"] == -1):\n",
    "            time_independent_df.loc[index] = row\n",
    "            a = updated_stock_data.iloc[index][\"poly_fit_close\"]\n",
    "        elif (updated_stock_data.at[index,\"maxima\"] == 1):\n",
    "            time_independent_df.loc[index] = row\n",
    "            a = updated_stock_data.iloc[index][\"poly_fit_close\"]\n",
    "\n",
    "    # Reset time dependent index\n",
    "    # Set new time independent index\n",
    "\n",
    "    time_independent_df.reset_index(inplace = True)\n",
    "    time_independent_df.rename(columns={\"index\":\"time_dependent_index\"}, inplace = True)\n",
    "\n",
    "    return time_independent_df\n",
    "\n",
    "# time_independent_df = time_independent_data(updated_stock_data)\n",
    "# time_independent_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee0f36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify daily double top/bottom patterns\n",
    "# Inherently there should only be 1 identification of the pattern as it is considered a trend reversal pattern\n",
    "# The loop will break once the pattern is identified\n",
    "\n",
    "def identify_double_patterns(time_independent_df, updated_stock_data):\n",
    "\n",
    "    # Initialize variables to identify double top/bottom patterns\n",
    "    # Time dependent variable x_0 will always begin at a local min/max which also coincides\n",
    "    # With the start of a trend into a potential double top/bottom\n",
    "    \n",
    "    x_0 = 0\n",
    "\n",
    "    # Initiation of double top/bottom variable\n",
    "    \n",
    "    a = 0\n",
    "\n",
    "    # First peak/valley of double top/bottom pattern\n",
    "    \n",
    "    b = 0\n",
    "\n",
    "    # Trough/peak of double top/bottom pattern\n",
    "\n",
    "    c = 0\n",
    "\n",
    "    # Second peak/vallye of double top/bottom pattern\n",
    "    \n",
    "    d = 0\n",
    "\n",
    "    # Trigger of double top/bottom pattern\n",
    "    \n",
    "    e = 0\n",
    "\n",
    "    # Final time increment to finalize and trigger double top signal\n",
    "    \n",
    "    x_f = 0\n",
    "\n",
    "    # Read through code to identify double top/bottom and assign to target columns.\n",
    "\n",
    "    for index, row in islice(time_independent_df.iterrows(), 0, len(time_independent_df) - 4):\n",
    "\n",
    "        # Check for double top\n",
    "        # If found then assigns x_f final time for writing to targets in time dependent dataframe\n",
    "\n",
    "        if (time_independent_df.at[index,\"minima\"] == -1):\n",
    "            a = time_independent_df.iloc[index][\"poly_fit_close\"]\n",
    "            b = time_independent_df.iloc[index + 1][\"poly_fit_close\"]\n",
    "            c = time_independent_df.iloc[index + 2][\"poly_fit_close\"]\n",
    "            d = time_independent_df.iloc[index + 3][\"poly_fit_close\"]\n",
    "            e = time_independent_df.iloc[index + 4][\"poly_fit_close\"]\n",
    "            x_0 = time_independent_df.iloc[index][\"time_dependent_index\"]\n",
    "\n",
    "            if (time_independent_df.iloc[index + 1][\"poly_fit_low\"]) < d < (time_independent_df.iloc[index + 1][\"poly_fit_high\"]) and (e < c):\n",
    "                x_f = time_independent_df.iloc[index + 4][\"time_dependent_index\"]\n",
    "                while (x_0 < x_f + 1):\n",
    "                    updated_stock_data.at[x_0, \"dbl_top_target\"] = 1\n",
    "                    x_0 = x_0 + 1\n",
    "                break\n",
    "\n",
    "        # Check for double bottom\n",
    "        # If found then assigns x_f final time for writing to targets in time dependent dataframe\n",
    "            \n",
    "        elif (time_independent_df.at[index,\"maxima\"] == 1):\n",
    "            a = time_independent_df.iloc[index][\"poly_fit_close\"]\n",
    "            b = time_independent_df.iloc[index + 1][\"poly_fit_close\"]\n",
    "            c = time_independent_df.iloc[index + 2][\"poly_fit_close\"]\n",
    "            d = time_independent_df.iloc[index + 3][\"poly_fit_close\"]\n",
    "            e = time_independent_df.iloc[index + 4][\"poly_fit_close\"]\n",
    "            x_0 = time_independent_df.iloc[index][\"time_dependent_index\"] \n",
    "\n",
    "            if (time_independent_df.iloc[index+1][\"poly_fit_low\"]) < d < (time_independent_df.iloc[index+1][\"poly_fit_high\"]) and (e > c):\n",
    "                x_f_min = time_independent_df.iloc[index + 4][\"time_dependent_index\"]\n",
    "                while (x_0 < x_f + 1):\n",
    "                    updated_stock_data.at[x_0, \"dbl_bot_target\"] = 1\n",
    "                    x_0 = x_0 + 1\n",
    "                break\n",
    "            \n",
    "    return updated_stock_data, x_f\n",
    "\n",
    "# updated_stock_data, x_f = identify_double_patterns(time_independent_df,updated_stock_data)\n",
    "\n",
    "# print(x_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13dae4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Checking\n",
    "\n",
    "# display(updated_stock_data.head(20))\n",
    "# print(updated_stock_data.loc[x_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "548d58f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-03 00:00:00-05:00\n",
      "2021-02-04 00:00:00-05:00\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb#X14sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m# Fetch stock data for the current day\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     stock_data \u001b[39m=\u001b[39m get_stock_data(api, stock_symbol, time_frame, current_date_iso, next_day_date_iso)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb#X14sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     updated_stock_data \u001b[39m=\u001b[39m polynomial_min_max_fit(stock_data, polynomial_degree)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb#X14sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m#, min_length, y_polynomial_close, local_poly_minima, local_poly_maxima\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb#X14sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     time_independent_df \u001b[39m=\u001b[39m time_independent_data(updated_stock_data)\n",
      "\u001b[1;32m/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpolynomial_min_max_fit\u001b[39m(stock_data, polynomial_degree):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     min_length \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mlen\u001b[39m(stock_data\u001b[39m.\u001b[39mindex), \u001b[39mlen\u001b[39m(stock_data[\u001b[39m'\u001b[39;49m\u001b[39mclose\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     x_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(min_length)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ebrown/Desktop/TheTrendIsYourFriend/TrendIsYourFriend_1.1.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Polynomial fitting\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'"
     ]
    }
   ],
   "source": [
    "# Loop to collect and assess daily data one day at a time\n",
    "\n",
    "current_date = datetime.datetime.fromisoformat(start_date)\n",
    "next_day_date = current_date + datetime.timedelta(days=1)\n",
    "\n",
    "master_df = {\n",
    "    'timestamp': [],  # List of timestamps\n",
    "    'close': [],      # List of close prices\n",
    "    'high': [],       # List of high prices\n",
    "    'low': [],        # List of low prices\n",
    "    'trade_count': [], # List of trade counts\n",
    "    'open': [],       # List of open prices\n",
    "    'volume': [],     # List of volumes\n",
    "    'vwap': [],       # List of volume-weighted average prices\n",
    "    'poly_fit_open': [],    # List of polynomial fit open prices\n",
    "    'poly_fit_high': [],    # List of polynomial fit high prices\n",
    "    'poly_fit_low': [],     # List of polynomial fit low prices\n",
    "    'poly_fit_close': [],   # List of polynomial fit close prices\n",
    "    'minima': [],           # List of minima\n",
    "    'maxima': [],           # List of maxima\n",
    "    'dbl_top_target': [],   # List of double top targets\n",
    "    'dbl_bot_target': []    # List of double bottom targets\n",
    "}\n",
    "\n",
    "daily_dataframes = []\n",
    "\n",
    "master_df = pd.DataFrame(master_df)\n",
    "\n",
    "print(current_date)\n",
    "print(next_day_date)\n",
    "\n",
    "while current_date <= pd.Timestamp(end_date):\n",
    "\n",
    "    # Convert current_date to ISO format for API call\n",
    "\n",
    "    current_date_iso = current_date.isoformat()\n",
    "\n",
    "    # Calculate the next day\n",
    "\n",
    "    next_day_date = current_date + datetime.timedelta(days=1)\n",
    "\n",
    "    # Convert next_day_date to ISO format for API call\n",
    "\n",
    "    next_day_date_iso = next_day_date.isoformat()\n",
    "\n",
    "    # Fetch stock data for the current day\n",
    "\n",
    "    stock_data = get_stock_data(api, stock_symbol, time_frame, current_date_iso, next_day_date_iso)\n",
    "\n",
    "    updated_stock_data = polynomial_min_max_fit(stock_data, polynomial_degree)\n",
    "#, min_length, y_polynomial_close, local_poly_minima, local_poly_maxima\n",
    "    time_independent_df = time_independent_data(updated_stock_data)\n",
    "\n",
    "    updated_stock_data, x_f = identify_double_patterns(time_independent_df, updated_stock_data)\n",
    "\n",
    "    # Perform your analysis or call your functions here\n",
    "    # e.g., identify_double_patterns(time_independent_df, updated_stock_data)\n",
    "\n",
    "    daily_dataframes.append(updated_stock_data)\n",
    "\n",
    "    del stock_data\n",
    "    del updated_stock_data\n",
    "    del time_independent_df\n",
    "\n",
    "    # Increment to the next day\n",
    "    \n",
    "    current_date = next_day_date\n",
    "\n",
    "    master_df = pd.concat(daily_dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.info()\n",
    "print(len(master_df))\n",
    "display(master_df.head(50))\n",
    "display(master_df.tail(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74963cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
